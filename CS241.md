---
layout: default
title: Operating Systems and Computer Networks
math: true
---

# CS241 - Operating Systems and Computer Networks

## What is an Operating System

No universally accepted definition

- A software acting as an intermediary between the user of a device and the hardware of the device.



Computer system hardware resources:

- CPU
- Memory
- I/O devices
- Storage

The OS is responsible for allocating these resources to user processes and control their execution. A process is a program in execution

- The goal is to avoid failures and errors - two programs attempting to write to the same memory simultaneously

### OS structure

![image-20211012085716795](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211012085716795.png)

### Operating System Services

These can be broken down into two categories:

- Those which are useful to the user (Program execution, IO, File System Management)
- Those which are beneficial to the system (Security, memory allocation)

#### Program Execution

- Load a program into memory
- Execute that program
- Stop that program

#### IO Operations

- While running a program, the computer may be required to perform IO
- For efficiency and protection, users cannot control devices directly
- This OS controls IO devices through device drivers and interrupts
  - More efficient because the users tdo not need to write code to perform IO - call high level routines
  - More secure because multiple programs cannot access the same IO simultaneously

#### File System Management

Programs need to:

- Read/write files and directors
- Perform additional operations - copy/move
- These permissions may be subject to permission management

The OS system provides system calls to achieve these.

#### Communications

Sometimes, one process may need to communicate with another

- communication may  occur between processes that are on the same computer, or a different computer across a network
- This may be implemented by shared memory or message passing

![image-20211012090929711](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211012090929711.png)

#### Error Handling

The OS must constantly be detecting and correcting errors. This may result in:

- The CPU and memory hardware
- The IO devices
- Illegal memory access

The OS handles the errors wither by invoking an error handling routine or shutting down the process.

#### Resource allocation

- When there are multiple users or multiple jobs running simultaneously, resource must be allocated to each
- In scheduling CPU jobs the OS must consider the speed of the processor, the number of available processors, the jobs to be executed etc.

#### Accounting

- Necessary to keep track of which processes are running and how much computing resource they resume 
- This may be used for system admin, or billing users (cloud computing)
- The OS gathers this info through process control blocks

#### Protection and Security

- When separate processes execute concurrently they should not be able ti interfere with the other processes or with the OS itself
- Security of the system from outside threats is also important.
  - Encryption and Authentication

### The Kernel

- The core of an OS
- It is loaded into the main memory at system startup
- Is is the process running at all times
- Certain functions only the kernel can perform
  - Memory management, process scheduling, file handling

#### Kernel Space Vs User Space

**Kernel space** the part of the memory where the kernel executes

**User space** is the section of memory where the user processes run

- Kernel space is kept protected from user space
- Can be accessed via user processes through system calls
  - Perform services like IO operation or process creation

#### System Calls

- When a user process requires a service from the kernel it invokes a system call
- Required since user processes cannot perform certain privileged operations
- Low level functions provided by the OS
- Provide a consistent interface for common operations

#### Dual Mode Operation

- A mechanism to distinguish between OS and user oprtations
- Hardware operates in two modes
  - User mode
  - Kernel mode
- A mode bit indicates user or kernel mode
- Some instructions designates as privileged only executable in kernel mode
  - System calls by a user asking the OS to perform some function changes the hardware from user to kernel mode
  - Return from the system call resets the mode to user mode

 ##### Transition from User to Kernel Mode

![image-20211012093440301](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211012093440301.png)

### Operating System Structures

- Large and complex software projects
- Common to partition the task into small components rather than one huge monolithic system

#### Simple Structures

- Many early were not well defined
- In the era, the hardware did not support dual mode operation

- MS-DOS also limited by hardware constraints; and consisted of two parts:
  - The kernel - this is then divided into a number of interfaces and device drivers
  - System programs.
-  Large amounts of functionality was contained in a single level
- Difficult to maintain, but beneficial due ti the fact where was very little overhead in the system call interface.

#### A Layered Approach

With proper hardware support, a modular design is possible

- this can be achieved through separationof layers
- The bottom layer is the hardware and the top layer is the users

- Layer K, users the service of layer K-1 and provides to K+1

##### Pros and Cons

Pros:

- Simplicity of construction - easy to modify without changing the implementation
- Ease of debugging
- Clear interfaces between layers

Cons:

- Defining layers is difficult - one must be careful that a layer below never requires a process from a layer above
- Efficiency - system calls access multiiple layers to execute which adds overhead

#### Microkernels

- The Mach OS modularised the kernel using a microkernel approach
- Remove all non-essential components from the kernel and implement them as either system or user-level programs
- Results in a smaller kernel
  - Only provide minimal process and memory management and inter-process communication

![image-20211012094447819](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211012094447819.png)



##### Pros and Cons

Pros:

- Extending the OS is easy - only implement the essential services, all new services are added to the user space, the changes tend to be fewer as it has a smaller size
- More security and reliability - more services are running in the user space

Cons:

- Performance suffers due to increased system call overhead
  - Windows NT was much slower than Windows 96

#### Loadable Kernel Modules

- Most modern approach to system design involves this
- Common in modern implementations of UNIX, OS X and windows
- Kernel provides core services, while other services are implemented dynamically as the kernel is running
- Similar to layered, as each section is well defined, however any module can call any other module
- Similar to micro-kernel, as kernel only implements the basic functionality

![image-20211012094833429](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211012094833429.png)

## Processes

### What is a process

-  Program in execution
- A passive entitit stored on disk as an executeable file
- A process is active
  - A program becomes a process when it is loaded into memory. Execution can be started by many methods 
  - One program can lead to many processes

### A Process in Memory

In a 32 bit system or program, the largest memory address that can be indexed is 32 binary 1s

- **Text** - stores the instruction
- **Data** - stores the global variables
- **Heap** - dynamically allocated memory
- **Stack** - stores variables and function parameters such as the return address if a function
- The space between stack and heap allow them to grow or shrink during the program run time.

![image-20211020111141086](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211020111141086.png) - The empty space represents the space for the heap and stack to grow - stack down and heap up

#### Process States and State Changes

- New - the process is being created

- Running - the instructions are being executed

- Waiting - The process is waiting for some event to occur

- Ready - The process is waiting to be assigned toa processir

- Terminated - the Process has finished execution

  ![image-20211020111353631](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211020111353631.png)

The process may change states multiple time, for example when an interrupt is called, the process will go from running to ready, whilst waiting for the program to be ready.

- This is called context switching

#### Process Control Block - PCB

A data structure to keep track of a process over its entire lifetime, there is a PCB for each process in operation.

- Process state - running, waiting, ready
  - OS maintains a wueue for each process state for each process which is  in that particular state
- Program counter - location o the next execution
  - Needed when the process transitions from the running to ready, to return to the point of where it was previously
- CPU registers - contents of the CPU registers
  - Store important results of CPU computations - these need to be reloaded after interrupt
- CPU scheduling information -  priorities scheduling, queue pointers
  - Handles interrupts?
- Memory management information - memory allocated to the process
  - Helps the process be allocated in memory - page table or segment table of a process
- Accountings information - CPU used, time since start.
  - Useful to manage a system effectvively
- I/O status - list of open files I/O devices etc.
  - Helps to avoid synchronisation errors of processes trying to write to the same file simultaneously.

![image-20211020111901484](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211020111901484.png)

##### Keeping Track Of the Process

- In order to keek track of the state of each process, the OS stores info about it
- Info stored in the PCB
- Since the process control block contains critical information on the process, it must be stored in an area of memory protected from normal user access

#### Concurrency and Context Switches

- Done by context switching, one processor cannot execute more than one at a time. therefore context switching is needed
  - First the OS saves the context of the current process inc. program counter and cpu registers into the PCB of the process, when starting the process up again, the context is loaded back into memory

![image-20211020112402541](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211020112402541.png)

- Context switch between two processes - P0 is saved, and P1 is loaded in. 
  - Time spend in the context switch is pure overhead as no actual computation is performed here.
  - May be done with proper hardware support

- when the CPU switches to another process
  - the system saves the stae of the current process in the process control block
  - The system loads the save state of the new process
- Called a context switch
- The more complex the OS and the PCB, the more overhead cost there is



#### Process Scheduling

- To maximise CPU use, quickly switch processes onto the CPU for time sharing
- Process Scheduler selects among available processes for next execution on the CPU
- Maintain scheduling queues of processes
  - Job queue - set of all processes iin the new state - long term scheduler - not invoked as often
  - Ready queue - set of all processes in the ready state - short term scheduler - invoked often
  - Device queues - set of all processes waiting for an IO device

##### Ready and device Queues

![image-20211020113055479](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211020113055479.png)

Queues formed of the PCB’s of different devices

- to maintain the ready queue, the header holds a pointer of the first and last PCB in the queue, each PCB contains a pointer to the next in the queue

##### Queueing Diagram

During the lifetime, the provess moves from one queue to another. The processes in the ready queue wait to be operated by the CPU.

Whist it is being served, multiple things can happen

- Process can stop execution to perfrom some IO operation
  - Moves the the corresponding IO device queue
  - On completion returns to the ready queu
- Process execution may be interrupted as the time slice has expired
  - Moved back to the ready queue
- Can create a child process
- Parent process after waiting for the child process to execute returns to the ready queue
- Continues moving between during its lifetime
- On execution completion, it is removed from all queues and PCBs are cleared.

![image-20211020113243907](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211020113243907.png)

##### Short term Scheduler

- Selects the next process to be execute from memory
  - Invoked v frequently - once every 100 ms

- Must be fast - if it takes 10ms to decide a process a burst for 100 ms - 9% of time is wasted

##### Long term Scheduler

Selects processes in the new state to be brought into the main memory in the ready queue

- Invoked much less frequent - may be minutes between creating once process and the next
- Controls the degree of multiprogamming
  - If this is stable, tha arrival rate of jobs is equal to the completion rate
- Processes can be described as:
  - IO Bound - spends more time doing IO that computation - short CPU bursts
  - CPU bound - spends more time doing computation  - long CPU bursts
  - Long term scheduler strives for good process mix
- Time sharing systems like Linux and Windows dont have a long-term scheduler
  - All processes are dumped on the short term



### Process Creation

A process (child process) may be created by another process (parent process)

- Children processes can in turn create others, forming a process tree
- Processes are usually identified and managed via a process identifier - PID

![image-20211020114742423](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211020114742423.png)

#### Process Creation Options

On process creation, the process has a set of options that are selected. 

**Resource sharing options**

- Parent and children share all resource
- Children share subset of parent resources
- Parent and child share no resources

**Execution Options**

- Parent and children execute concurrently
- Parent waits until children terminate

**Address Space Options**

- The child’s address space is a duplicate of that of its parent - has the same code, data and stack as the parent
- The child loads a new program into its address space.

#### Process Creation In Unix

- Th fork() system call creates a new process with a duplicate address space of the parent
- The exec() system call is used after fork() to replace the address space of the child process with a new program

### Process Termination

- Terminates automatically when the last statement has been executed

- A process can be also terminated using the exit() call
- Return stats value (exit code) to parent
- All resources of the process are released by the OS

![image-20211020121912579](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211020121912579.png)

- After a child process has terminated, and before its exeit status is colllected by the parent process, the child is said to be a zombie process
- During this, all resources of the child are released but its entry still remains in the process table
- Once the parent receives the exit status, the entry is released from the process table.

#### What happens if the parent exits without Invoking wait

- The children processes are now orphan processes
- In UNIX systems, the init process is assigned to the parent
- The init process preiodically issues the wait() to collect exit status of all orphan processes
  - Allows the exit status to be collcted and releases the orphans pid and process tabe entry

#### Abort System Call

Can terminate the execution of child processes using the abort() system call

- child has exceeded its allocated resources
- Task assigned to child is no longer required
- The parent is exiting and the operating system does not allow a child to continue if its parent terminates - Cascading Termination

### Inter Process Communication - IPC

- Processes running concurrently may want to communicate with each other

  - Two processes may want to communicate to complete a task

  - The data produced by one could be needed by another

Two main mechanisms

#### Shared Memory

- shared memory - a region of memory that is shared by communicating processes is established
  - Two communicate read and write to a shard part of the memory - usually lies within the address space of one of the processes and the other will need access to this space
  - Special permission from the OS is required for one process toa ccess the memory space of the other
    - Need kernel intervention
  - System calls are used only to establish the shared part of the memory 
    - No further intervention from the kernel
    - Less overhead cost
    - harder job for the programmer to make sure that the processes maintain synchronisation - ensure both are not trying to write from simultaneously.
  - Once the kernel has intervened, the processes must ensure they do not overwrite

##### Producer-Consumer Paradigm

- **Producer** -a process which produces information

- **Consumer** - a process which consumes the produced information

Can be both but not simulatneously

- The shard memory/buffer space can be filled by the producer and emptied by the consumer
- Consumer must wait when the buffer is empty
- Producer must wait when the buffer is full
  - When the buffer space is practically unbounded, there is no issue

##### Shared buffer as circular queue

- Still has a beginning and end, in and out, prod writes to in, and consumer reads from out. As items added, in is incremented until buffer is full
- Is full when one space left - or said to be full
- When emptying, as items are emptied, the out end is incremented until empty - when the in and out point to the same location - this is why we cannot distinguish when full or empty if no space is left.

![image-20211020133252220](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211020133252220.png)

To calculate, use the modulo of the size of the buffer due to the fact that the data structure is a circle

- To get around this



#### Message Passing

- Message Passing - messages are exchanged between the communicating processes
  - Two communicate by sending messages between each other
  - Kernel provides a medium 
    - Often a buffer
    - They will write or read to the buffer to get the memory

![image-20211020132324537](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211020132324537.png)

- should provide two operations
- - send
  - Receive
- Generally implemented using system calls
  - Kernel’s responsibility to control these, hence the larger overhead

##### Implementation of send() and receive()

Depends on:

- Link implementation - direct or indirect
- Synchronisation between send() and receive()
- Buffer size representing the communication link

![image-20211020133750674](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211020133750674.png)

##### Direct Communication

Processes must name each other explicitly

- send(P, message)
- receive(Q, message) or receive(id, message) - not required to specify a sender

Properties of communication link

- established automatically
- A link is associated with exactly one pair of processes
- Hardcoding process identifier may not be ideal since every time a process is run its id can change 

##### Indirect communication

Messages are directed from mailboxes - ports

- each mailbox has a unique id: 
  - send(mailboxID, message)
  - receive(mailboxID, message)
- Can only communicate if they share a mailbox

Properties of link

- Link established only if processes share a common mailbox
- A link may be associated with many processes
- Each pair of processes may share several communication links

#### Synchronisation

Blocking is considered synchronous

- blocking send – the sender is blocked until the message is received
- blocking receive – the receive is blocked until a message is available

![image-20211020134741120](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211020134741120.png)

Non-blocking is considered asynchronous

- Non-clocking send  – the sender send the message and continue
- non-clocking receive – the receiver receives a valid message or a null message 



Different combinations of send and receive are possible

- you might use a nonblocking send() in combination with a blocking receive()
  - This allows the sending process to keep working without waiting for the receive to process the message
- The producer/consumer problems become trivial if using the blocking send() and receive() calls



#### Buffering

Communication link is a buffer. Implementation of send() and receive() depends on the capacity of the buffer

- 0 capacity - the queue’s a maximum length of zero, so sender must block until recipient receives the message
- Bounded capacity - the queue has finite length, when full the sender must block
- Unbounded capacity - the queue’s length is potentially infinite - sender never needs to block



#### Examples of IPC systems

- shared memory using mmap
- Pipes
- Named pipes



## Application Layer: client-server model, transport layer services and protocols, socket programming, HTTP

- Network components and functions
- Network delay and loss
- Packet Switching vs Circuit Switching
- Layered Structure off the internet

### What is a computer network

A network of inter-connected computing devices which enable processes running on different devices to communicate

- Processes communicate by sending messages
- Intermediate nodes help forward messages



#### Components of a network

- Network edge consists of end hosts, they run applications - Web, Email, Video streaming etc
  - Applications involve two communicating processes running on two different devices
- Packet Switches - help forward data packets - switch, router
- Communication links - carry data packets between network devices - wireless or wired

- End hosts connect through the internet through access points - routers, mobile towers
- APs are providered by ISPs
  - They are organised in hierarchical structures
- Internet is the network of ISPs

#### Functions of an End Host

1. Run application processes which generate messages
2. Breaks down application messages into smaller chunks called packets
3. Adds addition information - packet headers so that the packets can be carried by the internet to their destinations
   - Ip address: uniquely identifies an end host in the network
   - Port no: uniquely identifies a process running within an end host
4. Send bits over a physical medium
5. If needed, provides reliable and orderly delivery of packets
6. Controls the rate of transmission of packets - If needed. 

#### Functions of Access Points

Serve as an entry to the internet

- Different types using different technologies
  - Residential access nets use Ethernet and WIFI to connect to a home router
  - Institutional access networks use Ethernet and WIFI to connect to institutional router
  - Mobile access networks use 3G, 4G, or 5G to connect to the nearest base station
- Speeds of these networks depend on the technology being used

#### Functions of Network Core

The network core consists of packet switchers

- Find the route that an internet packet will take from source to destination
  - Runs a routing algorithm to construct routing tables
- Once a packet arrives at a router, it first checks the destination and finds the corresponding entry and forwards the packet to the corresponding outgoing link or router

##### Store and Forward Principle

- An entire packet must be received by a router before it is transmitted to the next link 
- Takes L/R seconds to transmit L-bit packets into link at R bits

![image-20211026082223655](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211026082223655.png)

- End to end delay = 2L/R seconds
- If L is large, the delay increases
  - Why the long messages are broken into smaller packets

##### Queueing delay, loss

If arrival rate in bits to link exceeds transmission rate of a link for a period of time:

- Packets will queue, wait to be transmitted on link
- Packets can be dropped if the memory buffer fills up

![image-20211026082437594](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211026082437594.png)

#### Four sources of Packet Delay

$d_{nodal}=d_{proc} + d_{queue} + d_{trans} + d_{prop}$ 

- $d_{proc}$ - nodal processing delay
  - Check bit errors
  - Determine output link - reading the packet header
  - typically < msec

- $d_{trans}$ - transmission delay
  - $L$ - packet length - bits
  - $R$ - link bandwidth - bps
  - $d_{trans}=L/R$
- $d_{queue}$ - Queueing delay
  - Time wasted at output link for transmission
  - Depends on congestion level of the router
- $d_{prop}$ - pro0pogation delay
  - $d$ - length of physical link
  - $s$ - propogation speed in medium - $\approx 2\cross 10^8ms^{-1}$
  - $d_{prop} = d/s$

#### Throughput 

Rate at which bits are transferred from a source to a destination in a given time window

- Instantaneous - rate at given point of time
- Average - rate over long period of time

Throughput is specific toa  flow or communicating pair

Instantaneous throughput at $t=\frac{\Delta s}{\Delta t}$

![image-20211026083316030](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211026083316030.png)

When another source begins to transmit to the same destination, the throughput of each flow will be reduced.

##### Scenario

- $R_s<R_c$ 
- $R_s>R_c$ - average throughput of the smallest in each scenario

The bottleneck link:

- the link on a end-end path which has the slowest throughput of all the other nodes in that link

### Protocols

- Communicating nodes must agree on certain rules
- Defines rules for communication
  - What to do is a message is received
  - Sequence and format of messages

“Protocols define format, order of messages sent and received among network entities, and actions takes on message transmission and receipt”

- These can be implemented with either software or hardware

#### Examples

- Routers run protocols to forwards messages
- NICs implement hardware protocols to send bits through a physical medium

#### **Standards**

- Most protocols defined by the IETF
- Some other bodies specify standards
  - IEEE does Ethernet and WIFI

### Data Transmission Techniques

#### Packet Switching

Internet uses packet switching

- Different flows share resources along their routes
- If one flow is not using any of the shared links, then the other flow can use it
- Flows can change root if needed

##### Pros and cons

- Resources are not pre allocated to a communicating pair of devices
  - Cons: packets may have to wait, may get lost
  - Pros: Better utilization of resources

#### Circuit Switching

Used in telephone networks

- a circuit is reserved for each flow for the entire call duration
- Flows do not share resources
- If one flow is not using its assigned circuit during the call, it cannot be used by another flow
- Not ideal for internet traffic which is busy by nature

##### Pros and Cons

- Resources are reserved for a communicating pair for the entire duration of communication - called a circuit
  - Pros - Guaranteed rate, no losses
  - Cons - Poor utilization or resources for bursty traffic

### Layering

- Network devices perform complex functions
- Better to divide these into layers
- Each layer performs a subset of functions
  - Layer $N$ uses the services of layer $(N-1)$, and provides services to layer $(N+1)$
- Makes it easier to add services to a layer or change its implementation without affecting others
  - Must make sure the basic functionality remains the same

#### The five layers

All layers may not need to be run

##### Application

Consists of user applications or processes which generate the data to be used across the internet.

A standard set of protocols for this layer is shown below.

- HTTP 
- SMTP
- DNS

##### Transport

Provides services to the application layer, it’s main job is to divide the data into packets, and add headers to the packets (transport layer headers), adding sequencing and error correcting information. An application layer program must specify which of the protocols it wants to use

- TCP
- UDP

##### Network

Adds a header to the packets generated by the transport layer - source and destination address. Runs a routing algorithm 

- IP
- Routing protocls

##### Link

Adds a source and destination MAC addresses to the segments generated by the network layer - identifies the NIC cards by the hardware. Every time the packet moves a hop in the internet, the source and destination MAC addresses change.

- Ethernet
- WIFI

##### Physical

Decides how individual bits are transmitted across the phyisical transmission medium

- Separate protocol for each transmission message



#### 

#### Encapsulation

The path taken by the message is identified by the blue path. The message after being generated, passes through each of the five layers at the source, nd then is transmitted. Each of the layers adds new headers to the message.

- Process of adding headers is called encapsulation

Headers are successively removed by the receiving node, until the message reaches the topmost layer within that node

- Only the end and start node run all five layers
  - Most complicated tasks are completed by the end nodes.

![image-20211026085632988](C:\Users\leonc\AppData\Roaming\Typora\typora-user-images\image-20211026085632988.png)

